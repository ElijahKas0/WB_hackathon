{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dbe4e926-5af7-4cd0-9a06-6d830d6c64f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # На случай открытия в Google Colab\n",
    "# # Установка основных библиотек\n",
    "# !pip install catboost lightgbm optuna scikit-learn pandas numpy scipy matplotlib seaborn\n",
    "\n",
    "# # Дополнительные зависимости (если нужны)\n",
    "# !pip install --upgrade scikit-learn  # Актуальная версия sklearn\n",
    "# !pip install imbalanced-learn        # Для работы с дисбалансом классов (если используется)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2cd4d5fd-03b2-4a20-8568-5588811916f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Основные библиотеки\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import warnings\n",
    "\n",
    "# Визуализация\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Машинное обучение и модели\n",
    "from catboost import CatBoostClassifier\n",
    "import lightgbm as lgb\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# Метрики и оценка\n",
    "from sklearn.metrics import (\n",
    "    classification_report, confusion_matrix,\n",
    "    precision_score, recall_score, f1_score, fbeta_score\n",
    ")\n",
    "\n",
    "# Предобработка данных\n",
    "from sklearn.preprocessing import (\n",
    "    OneHotEncoder, KBinsDiscretizer, StandardScaler,\n",
    ")\n",
    "from sklearn.feature_extraction import FeatureHasher\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from scipy.sparse import issparse\n",
    "\n",
    "# Разбиение данных и кросс-валидация\n",
    "from sklearn.model_selection import (\n",
    "    train_test_split, StratifiedKFold\n",
    ")\n",
    "\n",
    "# Оптимизация гиперпараметров\n",
    "import optuna\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d78a50d2-3999-499b-b8e5-1a4f1900047a",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'Task/df_train.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------\u001b[39m",
      "\u001b[31mFileNotFoundError\u001b[39m                   Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[3]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# Извлечение данных из csv-таблиц\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m df_train = \u001b[43mpd\u001b[49m\u001b[43m.\u001b[49m\u001b[43mread_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mTask/df_train.csv\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m      3\u001b[39m df_test = pd.read_csv(\u001b[33m'\u001b[39m\u001b[33mTask/df_test.csv\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m      5\u001b[39m \u001b[38;5;66;03m# Удаление дубликатов\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mC:\\VYZ MAI\\ML_hackaton\\env\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1026\u001b[39m, in \u001b[36mread_csv\u001b[39m\u001b[34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[39m\n\u001b[32m   1013\u001b[39m kwds_defaults = _refine_defaults_read(\n\u001b[32m   1014\u001b[39m     dialect,\n\u001b[32m   1015\u001b[39m     delimiter,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1022\u001b[39m     dtype_backend=dtype_backend,\n\u001b[32m   1023\u001b[39m )\n\u001b[32m   1024\u001b[39m kwds.update(kwds_defaults)\n\u001b[32m-> \u001b[39m\u001b[32m1026\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mC:\\VYZ MAI\\ML_hackaton\\env\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:620\u001b[39m, in \u001b[36m_read\u001b[39m\u001b[34m(filepath_or_buffer, kwds)\u001b[39m\n\u001b[32m    617\u001b[39m _validate_names(kwds.get(\u001b[33m\"\u001b[39m\u001b[33mnames\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[32m    619\u001b[39m \u001b[38;5;66;03m# Create the parser.\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m620\u001b[39m parser = \u001b[43mTextFileReader\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    622\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mor\u001b[39;00m iterator:\n\u001b[32m    623\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n",
      "\u001b[36mFile \u001b[39m\u001b[32mC:\\VYZ MAI\\ML_hackaton\\env\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1620\u001b[39m, in \u001b[36mTextFileReader.__init__\u001b[39m\u001b[34m(self, f, engine, **kwds)\u001b[39m\n\u001b[32m   1617\u001b[39m     \u001b[38;5;28mself\u001b[39m.options[\u001b[33m\"\u001b[39m\u001b[33mhas_index_names\u001b[39m\u001b[33m\"\u001b[39m] = kwds[\u001b[33m\"\u001b[39m\u001b[33mhas_index_names\u001b[39m\u001b[33m\"\u001b[39m]\n\u001b[32m   1619\u001b[39m \u001b[38;5;28mself\u001b[39m.handles: IOHandles | \u001b[38;5;28;01mNone\u001b[39;00m = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1620\u001b[39m \u001b[38;5;28mself\u001b[39m._engine = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_make_engine\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mengine\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mC:\\VYZ MAI\\ML_hackaton\\env\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1880\u001b[39m, in \u001b[36mTextFileReader._make_engine\u001b[39m\u001b[34m(self, f, engine)\u001b[39m\n\u001b[32m   1878\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mb\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m mode:\n\u001b[32m   1879\u001b[39m         mode += \u001b[33m\"\u001b[39m\u001b[33mb\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m-> \u001b[39m\u001b[32m1880\u001b[39m \u001b[38;5;28mself\u001b[39m.handles = \u001b[43mget_handle\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1881\u001b[39m \u001b[43m    \u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1882\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1883\u001b[39m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mencoding\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1884\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mcompression\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1885\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmemory_map\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmemory_map\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1886\u001b[39m \u001b[43m    \u001b[49m\u001b[43mis_text\u001b[49m\u001b[43m=\u001b[49m\u001b[43mis_text\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1887\u001b[39m \u001b[43m    \u001b[49m\u001b[43merrors\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mencoding_errors\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mstrict\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1888\u001b[39m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mstorage_options\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1889\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1890\u001b[39m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m.handles \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1891\u001b[39m f = \u001b[38;5;28mself\u001b[39m.handles.handle\n",
      "\u001b[36mFile \u001b[39m\u001b[32mC:\\VYZ MAI\\ML_hackaton\\env\\Lib\\site-packages\\pandas\\io\\common.py:873\u001b[39m, in \u001b[36mget_handle\u001b[39m\u001b[34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[39m\n\u001b[32m    868\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(handle, \u001b[38;5;28mstr\u001b[39m):\n\u001b[32m    869\u001b[39m     \u001b[38;5;66;03m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[32m    870\u001b[39m     \u001b[38;5;66;03m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[32m    871\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m ioargs.encoding \u001b[38;5;129;01mand\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mb\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m ioargs.mode:\n\u001b[32m    872\u001b[39m         \u001b[38;5;66;03m# Encoding\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m873\u001b[39m         handle = \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[32m    874\u001b[39m \u001b[43m            \u001b[49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    875\u001b[39m \u001b[43m            \u001b[49m\u001b[43mioargs\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    876\u001b[39m \u001b[43m            \u001b[49m\u001b[43mencoding\u001b[49m\u001b[43m=\u001b[49m\u001b[43mioargs\u001b[49m\u001b[43m.\u001b[49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    877\u001b[39m \u001b[43m            \u001b[49m\u001b[43merrors\u001b[49m\u001b[43m=\u001b[49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    878\u001b[39m \u001b[43m            \u001b[49m\u001b[43mnewline\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    879\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    880\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    881\u001b[39m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[32m    882\u001b[39m         handle = \u001b[38;5;28mopen\u001b[39m(handle, ioargs.mode)\n",
      "\u001b[31mFileNotFoundError\u001b[39m: [Errno 2] No such file or directory: 'Task/df_train.csv'"
     ]
    }
   ],
   "source": [
    "# Извлечение данных из csv-таблиц\n",
    "df_train = pd.read_csv('Task/df_train.csv')\n",
    "df_test = pd.read_csv('Task/df_test.csv')\n",
    "\n",
    "# Удаление дубликатов\n",
    "df_train = df_train.drop_duplicates()\n",
    "df_test = df_test.drop_duplicates()\n",
    "\n",
    "y_train_np = df_train['target'].to_numpy()\n",
    "y_test_np = df_test['target'].to_numpy()\n",
    "\n",
    "df_train.drop(columns=['target'], inplace=True)\n",
    "df_test.drop(columns=['target'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32fec30f-dd37-4010-8abe-6f614dea78b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Кодирование категориальных признаков\n",
    "categorical_cols = ['PaymentType', 'service']\n",
    "\n",
    "for i,df in enumerate([df_train, df_test]):\n",
    "    df.drop(columns=['user_id', 'CreatedDate', 'NmAge','number_of_ordered_items'], inplace=True)\n",
    "    df['IsPaid'] = df['IsPaid'].map({False: 0, True: 1})\n",
    "    \n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('cat', OneHotEncoder(handle_unknown='ignore'), categorical_cols)\n",
    "    ],\n",
    "    remainder='passthrough'\n",
    ")\n",
    "\n",
    "\n",
    "X_train_transformed = preprocessor.fit_transform(df_train)\n",
    "feature_names = preprocessor.get_feature_names_out()\n",
    "X_test_transformed = preprocessor.transform(df_test)\n",
    "feature_names_1 = preprocessor.get_feature_names_out()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a68bdfc-b70d-4a5b-8597-387726eb4da0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Преобразование X в numpy\n",
    "if issparse(X_train_transformed):\n",
    "    X_train_np = X_train_transformed.toarray()\n",
    "    X_test_transformed = X_test_transformed.toarray()\n",
    "else:\n",
    "    X_train_np = X_train_transformed\n",
    "\n",
    "# Учёт дисбаланса классов\n",
    "pos_weight = 6.9 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bd0426a-c639-48a6-b8e6-215e9035e495",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Гиперпараметры\n",
    "params = {\n",
    "    'objective': 'binary',\n",
    "    'metric': 'binary_logloss',\n",
    "    'boosting_type': 'gbdt',\n",
    "    'verbosity': -1,\n",
    "    'num_leaves': 80,\n",
    "    'max_depth': 8,\n",
    "    'learning_rate': 0.1,\n",
    "    'n_estimators': 150,\n",
    "    'min_child_weight': 20,\n",
    "    'lambda_l2': 0.3,\n",
    "    'min_data_in_leaf': 30,\n",
    "    'scale_pos_weight': pos_weight,\n",
    "    'random_state': 42,\n",
    "    'n_jobs': -1\n",
    "}\n",
    "\n",
    "# Обучение модели на всем тренировочном наборе\n",
    "model = lgb.LGBMClassifier(**params)\n",
    "model.fit(X_train_np, y_train_np)\n",
    "\n",
    "# Предсказание вероятностей на тесте\n",
    "y_proba_test = model.predict_proba(X_test_transformed)[:, 1]\n",
    "\n",
    "# Подбор лучшего порога\n",
    "thresholds = np.arange(0.75, 0.961, 0.01)\n",
    "best_threshold = 0.75\n",
    "best_metrics = {'precision': 0, 'recall': 0, 'f1': 0}\n",
    "\n",
    "for threshold in thresholds:\n",
    "    y_pred_test = (y_proba_test >= threshold).astype(int)\n",
    "    precision = precision_score(y_test_np, y_pred_test, zero_division=0)\n",
    "    recall = recall_score(y_test_np, y_pred_test)\n",
    "\n",
    "    if recall >= 0.06 and precision > best_metrics['precision']:\n",
    "        best_threshold = threshold\n",
    "        best_metrics = {\n",
    "            'precision': precision,\n",
    "            'recall': recall,\n",
    "            'f1': f1_score(y_test_np, y_pred_test)\n",
    "        }\n",
    "\n",
    "# Финальные метрики\n",
    "y_pred_test = (y_proba_test >= best_threshold).astype(int)\n",
    "\n",
    "print(f\"\\n🔍 Best threshold: {best_threshold:.2f}\")\n",
    "print(f\"Precision: {best_metrics['precision']:.4f}\")\n",
    "print(f\"Recall: {best_metrics['recall']:.4f}\")\n",
    "print(f\"F1-score: {best_metrics['f1']:.4f}\")\n",
    "print(\"\\nConfusion Matrix:\")\n",
    "print(confusion_matrix(y_test_np, y_pred_test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "74e2cae8-5422-42ff-9b44-f772340a0685",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'Task/df_train.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------\u001b[39m",
      "\u001b[31mFileNotFoundError\u001b[39m                   Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[4]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# Открытие датасетов\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m df_raw_train = \u001b[43mpd\u001b[49m\u001b[43m.\u001b[49m\u001b[43mread_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mTask/df_train.csv\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m      3\u001b[39m df_raw_test = pd.read_csv(\u001b[33m'\u001b[39m\u001b[33mTask/df_test.csv\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m      5\u001b[39m \u001b[38;5;66;03m# Удаление дубликатов\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mC:\\VYZ MAI\\ML_hackaton\\env\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1026\u001b[39m, in \u001b[36mread_csv\u001b[39m\u001b[34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[39m\n\u001b[32m   1013\u001b[39m kwds_defaults = _refine_defaults_read(\n\u001b[32m   1014\u001b[39m     dialect,\n\u001b[32m   1015\u001b[39m     delimiter,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1022\u001b[39m     dtype_backend=dtype_backend,\n\u001b[32m   1023\u001b[39m )\n\u001b[32m   1024\u001b[39m kwds.update(kwds_defaults)\n\u001b[32m-> \u001b[39m\u001b[32m1026\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mC:\\VYZ MAI\\ML_hackaton\\env\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:620\u001b[39m, in \u001b[36m_read\u001b[39m\u001b[34m(filepath_or_buffer, kwds)\u001b[39m\n\u001b[32m    617\u001b[39m _validate_names(kwds.get(\u001b[33m\"\u001b[39m\u001b[33mnames\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[32m    619\u001b[39m \u001b[38;5;66;03m# Create the parser.\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m620\u001b[39m parser = \u001b[43mTextFileReader\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    622\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mor\u001b[39;00m iterator:\n\u001b[32m    623\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n",
      "\u001b[36mFile \u001b[39m\u001b[32mC:\\VYZ MAI\\ML_hackaton\\env\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1620\u001b[39m, in \u001b[36mTextFileReader.__init__\u001b[39m\u001b[34m(self, f, engine, **kwds)\u001b[39m\n\u001b[32m   1617\u001b[39m     \u001b[38;5;28mself\u001b[39m.options[\u001b[33m\"\u001b[39m\u001b[33mhas_index_names\u001b[39m\u001b[33m\"\u001b[39m] = kwds[\u001b[33m\"\u001b[39m\u001b[33mhas_index_names\u001b[39m\u001b[33m\"\u001b[39m]\n\u001b[32m   1619\u001b[39m \u001b[38;5;28mself\u001b[39m.handles: IOHandles | \u001b[38;5;28;01mNone\u001b[39;00m = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1620\u001b[39m \u001b[38;5;28mself\u001b[39m._engine = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_make_engine\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mengine\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mC:\\VYZ MAI\\ML_hackaton\\env\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1880\u001b[39m, in \u001b[36mTextFileReader._make_engine\u001b[39m\u001b[34m(self, f, engine)\u001b[39m\n\u001b[32m   1878\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mb\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m mode:\n\u001b[32m   1879\u001b[39m         mode += \u001b[33m\"\u001b[39m\u001b[33mb\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m-> \u001b[39m\u001b[32m1880\u001b[39m \u001b[38;5;28mself\u001b[39m.handles = \u001b[43mget_handle\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1881\u001b[39m \u001b[43m    \u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1882\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1883\u001b[39m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mencoding\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1884\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mcompression\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1885\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmemory_map\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmemory_map\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1886\u001b[39m \u001b[43m    \u001b[49m\u001b[43mis_text\u001b[49m\u001b[43m=\u001b[49m\u001b[43mis_text\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1887\u001b[39m \u001b[43m    \u001b[49m\u001b[43merrors\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mencoding_errors\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mstrict\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1888\u001b[39m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mstorage_options\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1889\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1890\u001b[39m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m.handles \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1891\u001b[39m f = \u001b[38;5;28mself\u001b[39m.handles.handle\n",
      "\u001b[36mFile \u001b[39m\u001b[32mC:\\VYZ MAI\\ML_hackaton\\env\\Lib\\site-packages\\pandas\\io\\common.py:873\u001b[39m, in \u001b[36mget_handle\u001b[39m\u001b[34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[39m\n\u001b[32m    868\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(handle, \u001b[38;5;28mstr\u001b[39m):\n\u001b[32m    869\u001b[39m     \u001b[38;5;66;03m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[32m    870\u001b[39m     \u001b[38;5;66;03m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[32m    871\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m ioargs.encoding \u001b[38;5;129;01mand\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mb\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m ioargs.mode:\n\u001b[32m    872\u001b[39m         \u001b[38;5;66;03m# Encoding\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m873\u001b[39m         handle = \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[32m    874\u001b[39m \u001b[43m            \u001b[49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    875\u001b[39m \u001b[43m            \u001b[49m\u001b[43mioargs\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    876\u001b[39m \u001b[43m            \u001b[49m\u001b[43mencoding\u001b[49m\u001b[43m=\u001b[49m\u001b[43mioargs\u001b[49m\u001b[43m.\u001b[49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    877\u001b[39m \u001b[43m            \u001b[49m\u001b[43merrors\u001b[49m\u001b[43m=\u001b[49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    878\u001b[39m \u001b[43m            \u001b[49m\u001b[43mnewline\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    879\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    880\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    881\u001b[39m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[32m    882\u001b[39m         handle = \u001b[38;5;28mopen\u001b[39m(handle, ioargs.mode)\n",
      "\u001b[31mFileNotFoundError\u001b[39m: [Errno 2] No such file or directory: 'Task/df_train.csv'"
     ]
    }
   ],
   "source": [
    "# Открытие датасетов\n",
    "df_raw_train = pd.read_csv('Task/df_train.csv')\n",
    "df_raw_test = pd.read_csv('Task/df_test.csv')\n",
    "\n",
    "# Удаление дубликатов\n",
    "df_raw_train = df_raw_train.drop_duplicates()\n",
    "df_raw_test = df_raw_test.drop_duplicates()\n",
    "\n",
    "# Проверка начального числа строк\n",
    "print(f\"Количество строк в df_raw_train до обработки: {len(df_raw_train)}\")\n",
    "print(f\"Количество строк в df_raw_test до обработки: {len(df_raw_test)}\")\n",
    "\n",
    "# Проверка дубликатов\n",
    "print(f\"Количество дубликатов в df_raw_train: {df_raw_train.duplicated().sum()}\")\n",
    "print(f\"Количество дубликатов в df_raw_test: {df_raw_test.duplicated().sum()}\")\n",
    "\n",
    "# Кодирование категориальных признаков\n",
    "for df in [df_raw_train, df_raw_test]:\n",
    "    df['IsPaid'] = df['IsPaid'].map({False: 0, True: 1})\n",
    "    df['service'] = df['service'].map({'ordo': 1, 'nnsz': 2})\n",
    "    df['CreatedDate'] = pd.to_datetime(df['CreatedDate'])\n",
    "\n",
    "df_raw_train = pd.get_dummies(df_raw_train, columns=['PaymentType'], prefix='PaymentType', drop_first=True)\n",
    "df_raw_test = pd.get_dummies(df_raw_test, columns=['PaymentType'], prefix='PaymentType', drop_first=True)\n",
    "\n",
    "train = pd.DataFrame()\n",
    "test = pd.DataFrame()\n",
    "\n",
    "# Обработка Distance: обрезка выбросов и заполнение пропусков\n",
    "lower_quantile_dist = df_raw_train['Distance'].quantile(0.005)\n",
    "upper_quantile_dist = df_raw_train['Distance'].quantile(0.995)\n",
    "df_raw_train['Distance'] = df_raw_train['Distance'].clip(lower_quantile_dist, upper_quantile_dist).fillna(df_raw_train['Distance'].median())\n",
    "df_raw_test['Distance'] = df_raw_test['Distance'].clip(lower_quantile_dist, upper_quantile_dist).fillna(df_raw_test['Distance'].median())\n",
    "\n",
    "# Feature engineering\n",
    "train['log_distance'] = np.log1p(df_raw_train['Distance'])\n",
    "test['log_distance'] = np.log1p(df_raw_test['Distance'])\n",
    "\n",
    "# Признак: mean_percent_of_ordered_items\n",
    "lower_quantile_percent = df_raw_train['mean_percent_of_ordered_items'].quantile(0.005)\n",
    "upper_quantile_percent = df_raw_train['mean_percent_of_ordered_items'].quantile(0.995)\n",
    "train['mean_percent_of_ordered_items'] = np.log1p(df_raw_train['mean_percent_of_ordered_items'].clip(lower_quantile_percent, upper_quantile_percent))\n",
    "lower_quantile_percent_test = df_raw_test['mean_percent_of_ordered_items'].quantile(0.005)\n",
    "upper_quantile_percent_test = df_raw_test['mean_percent_of_ordered_items'].quantile(0.995)\n",
    "test['mean_percent_of_ordered_items'] = np.log1p(df_raw_test['mean_percent_of_ordered_items'].clip(lower_quantile_percent_test, upper_quantile_percent_test))\n",
    "\n",
    "# Нормализация и бининг\n",
    "scaler_percent = StandardScaler()\n",
    "train['mean_percent_of_ordered_items'] = scaler_percent.fit_transform(train[['mean_percent_of_ordered_items']])\n",
    "test['mean_percent_of_ordered_items'] = scaler_percent.transform(test[['mean_percent_of_ordered_items']])\n",
    "discretizer_percent = KBinsDiscretizer(n_bins=2, encode='ordinal', strategy='uniform')\n",
    "train['mean_percent_of_ordered_items'] = discretizer_percent.fit_transform(train[['mean_percent_of_ordered_items']])\n",
    "test['mean_percent_of_ordered_items'] = discretizer_percent.transform(test[['mean_percent_of_ordered_items']])\n",
    "\n",
    "# Признак: is_new_account\n",
    "train['is_new_account'] = (df_raw_train['DaysAfterRegistration'] < 1000).astype(int)\n",
    "test['is_new_account'] = (df_raw_test['DaysAfterRegistration'] < 1000).astype(int)\n",
    "\n",
    "# Добавление целевой переменной\n",
    "train['target'] = df_raw_train['target']\n",
    "test['target'] = df_raw_test['target']\n",
    "\n",
    "train_data = df_raw_train.drop(columns=['user_id', 'nm_id', 'CreatedDate'])\n",
    "test_data = df_raw_test.drop(columns=['user_id', 'nm_id', 'CreatedDate'])\n",
    "\n",
    "# print(df_raw_train.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e0b4d924-684b-40ac-8119-396569bf3235",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Best parameters found:\n",
      "iterations: 800\n",
      "depth: 9\n",
      "learning_rate: 0.1\n",
      "l2_leaf_reg: 50\n",
      "scale_pos_weight: 9\n",
      "min_data_in_leaf: 50\n",
      "max_ctr_complexity: 3\n",
      "0:\tlearn: 0.8308845\ttotal: 216ms\tremaining: 2m 52s\n",
      "100:\tlearn: 0.9348141\ttotal: 6.22s\tremaining: 43s\n",
      "200:\tlearn: 0.9489555\ttotal: 11s\tremaining: 32.8s\n",
      "300:\tlearn: 0.9620220\ttotal: 16.6s\tremaining: 27.6s\n",
      "400:\tlearn: 0.9714939\ttotal: 21.9s\tremaining: 21.8s\n",
      "500:\tlearn: 0.9763866\ttotal: 27s\tremaining: 16.1s\n",
      "600:\tlearn: 0.9801995\ttotal: 31.6s\tremaining: 10.5s\n",
      "700:\tlearn: 0.9838970\ttotal: 37.2s\tremaining: 5.26s\n",
      "799:\tlearn: 0.9862749\ttotal: 42.2s\tremaining: 0us\n",
      "\n",
      "Best threshold: 0.96\n",
      "Validation Precision: 0.9990\n",
      "Validation Recall: 0.7301\n",
      "\n",
      "Test Metrics:\n",
      "Precision: 0.8496\n",
      "Recall: 0.0626\n",
      "[[12434    20]\n",
      " [ 1693   113]]\n"
     ]
    }
   ],
   "source": [
    "# Подготовка данных\n",
    "def prepare_data(df):\n",
    "    if 'Unnamed: 0' in df.columns:\n",
    "        df = df.drop(columns=['Unnamed: 0'])\n",
    "    return df\n",
    "\n",
    "train_data = prepare_data(train_data)\n",
    "test_data = prepare_data(test_data)\n",
    "\n",
    "X_train = train_data.drop(columns=['target'])\n",
    "y_train = train_data['target']\n",
    "X_test = test_data.drop(columns=['target'])\n",
    "y_test = test_data['target']\n",
    "\n",
    "# Выравнивание признаков\n",
    "for col in set(X_train.columns) - set(X_test.columns):\n",
    "    X_test[col] = 0\n",
    "for col in set(X_test.columns) - set(X_train.columns):\n",
    "    X_train[col] = 0\n",
    "X_test = X_test[X_train.columns]\n",
    "\n",
    "# Разделение на train/val\n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    X_train, y_train,\n",
    "    test_size=0.2,\n",
    "    stratify=y_train,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "# Лучшие параметры\n",
    "best_params = {'iterations': 800,\n",
    "               'depth': 9,\n",
    "               'learning_rate': 0.1,\n",
    "               'l2_leaf_reg': 50,\n",
    "               'scale_pos_weight': 9,\n",
    "               'min_data_in_leaf': 50,\n",
    "               'max_ctr_complexity': 3}\n",
    "\n",
    "print(\"\\nBest parameters found:\")\n",
    "for k, v in best_params.items():\n",
    "    print(f\"{k}: {v}\")\n",
    "\n",
    "# Финальная модель\n",
    "final_model = CatBoostClassifier(\n",
    "    **best_params,\n",
    "    eval_metric='F1',\n",
    "    verbose=100,\n",
    "    allow_writing_files=False\n",
    ")\n",
    "\n",
    "final_model.fit(\n",
    "    pd.concat([X_train, X_val]),\n",
    "    pd.concat([y_train, y_val]),\n",
    "    plot=False\n",
    ")\n",
    "\n",
    "# Подбор порога\n",
    "y_val_proba = final_model.predict_proba(X_val)[:, 1]\n",
    "thresholds = np.linspace(0.5, 0.96, 10)\n",
    "best_threshold = 0.5\n",
    "best_metrics = {'precision': 0, 'recall': 0}\n",
    "\n",
    "for thresh in thresholds:\n",
    "    y_val_pred = (y_val_proba >= thresh).astype(int)\n",
    "    precision = precision_score(y_val, y_val_pred, zero_division=0)\n",
    "    recall = recall_score(y_val, y_val_pred)\n",
    "\n",
    "    if precision >= 0.8 and recall >= 0.1 and precision > best_metrics['precision']:\n",
    "        best_metrics = {'precision': precision, 'recall': recall}\n",
    "        best_threshold = thresh\n",
    "\n",
    "print(f\"\\nBest threshold: {best_threshold:.2f}\")\n",
    "print(f\"Validation Precision: {best_metrics['precision']:.4f}\")\n",
    "print(f\"Validation Recall: {best_metrics['recall']:.4f}\")\n",
    "\n",
    "# Оценка на тестовых данных\n",
    "y_test_proba = final_model.predict_proba(X_test)[:, 1]\n",
    "y_test_pred = (y_test_proba >= best_threshold).astype(int)\n",
    "\n",
    "print(\"\\nTest Metrics:\")\n",
    "print(f\"Precision: {precision_score(y_test, y_test_pred, zero_division=0):.4f}\")\n",
    "print(f\"Recall: {recall_score(y_test, y_test_pred):.4f}\")\n",
    "print(confusion_matrix(y_test, y_test_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0dae07bc-9919-4e63-9836-ecc2a947a195",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TP только у LGBM: 72\n",
      "TP только у Catboost: 72\n",
      "Общее количество уникальных TP: 185\n"
     ]
    }
   ],
   "source": [
    "# True Positives - TP\n",
    "TP_lgbm_indices = np.where((y_pred_test == 1) & (y_test_np == 1))[0]\n",
    "TP_catboost_indices = np.where((y_test_pred == 1) & (y_test_np == 1))[0]\n",
    "\n",
    "# Разные TP (уникальные для каждой модели)\n",
    "only_lgbm_TP = np.setdiff1d(TP_lgbm_indices, TP_catboost_indices)\n",
    "only_logreg_TP = np.setdiff1d(TP_catboost_indices, TP_lgbm_indices)\n",
    "\n",
    "# Все уникальные TP\n",
    "all_unique_TP = np.union1d(TP_lgbm_indices, TP_catboost_indices)\n",
    "\n",
    "# Вывод\n",
    "print(\"TP только у LGBM:\", len(only_lgbm_TP.tolist()))\n",
    "print(\"TP только у Catboost:\", len(only_logreg_TP.tolist()))\n",
    "print(\"Общее количество уникальных TP:\", len(all_unique_TP))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8767a94a-3b86-4301-b280-ee44094e678e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TN только у LGBM: 14\n",
      "TP только у Catboost: 18\n",
      "Общее количество уникальных TP: 34\n"
     ]
    }
   ],
   "source": [
    "# False Positives - FP\n",
    "FP_lgbm_indices = np.where((y_pred_test == 1) & (y_test_np == 0))[0]\n",
    "FP_catboost_indices = np.where((y_test_pred == 1) & (y_test_np == 0))[0]\n",
    "\n",
    "# Разные FP (уникальные для каждой модели)\n",
    "only_lgbm_FP = np.setdiff1d(FP_lgbm_indices, FP_catboost_indices)\n",
    "only_logreg_FP = np.setdiff1d(FP_catboost_indices, FP_lgbm_indices)\n",
    "\n",
    "# Все уникальные FP\n",
    "all_unique_FP = np.union1d(FP_lgbm_indices, FP_catboost_indices)\n",
    "\n",
    "# Вывод\n",
    "print(\"TN только у LGBM:\", len(only_lgbm_FP.tolist()))\n",
    "print(\"TP только у Catboost:\", len(only_logreg_FP.tolist()))\n",
    "print(\"Общее количество уникальных TP:\", len(all_unique_FP))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b038485b-5997-49e5-978d-d43a0429d603",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Количество честных покупателей: 12454\n",
      "Количество мошенников: 1806\n",
      "Итоговая точность hard voting-like модели:0.845\n",
      "Итоговая полнота hard voting-like модели:0.102\n"
     ]
    }
   ],
   "source": [
    "#Вычисление precision и recall для модели hard voting-like\n",
    "\n",
    "# Подсчет количества 0 и 1 в тестовой выборке\n",
    "target_1_test = np.sum(y_test_np)  \n",
    "target_0_test = len(y_test_np) - target_1_test  \n",
    "\n",
    "print(f\"Количество честных покупателей: {target_0_test}\")\n",
    "print(f\"Количество мошенников: {target_1_test}\")\n",
    "\n",
    "# Итоговая точность и полнота\n",
    "precision = len(all_unique_TP)/(len(all_unique_TP)+len(all_unique_FP))\n",
    "recall = len(all_unique_TP)/target_1_test\n",
    "print(f\"Итоговая точность hard voting-like модели:{precision:.3f}\")\n",
    "print(f\"Итоговая полнота hard voting-like модели:{recall:.3f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (myenv_1)",
   "language": "python",
   "name": "env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

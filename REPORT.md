# Хакатон: Отчет о проделанной работе

## 1. Обзор данных
- **Формат данных**: CSV (`df_train.csv`, `df_test.csv`)
- **Размеры**:
  - Обучающая выборка: 105 556 записей
  - Тестовая выборка: 14 262 записи
- **Колонки**:
  - Всего: 22 (21 признак + целевая переменная `target`)
  - Типы данных: `int`, `float`, `bool`, `object`
- **Целевая переменная**: `target`
  - метка `0` — обычный заказ
  - метка `1` — мошеннеческий заказ
- **Дисбаланс классов**:
  - Обучающая выборка: 13 354 объектов класса `1` и 92 211 класса `0`
  - Тестовая выборка: 1 806 объектов класса `1` и 12 456 класса `0`
- **Повторяющиеся записи**:
  - Обнаружено 654 дубликата в `train` и 2 в `test`

## 2. Подход
### Предобработка данных
- Удаление дубликатов
- Кодирование категориальных признаков:
  - `IsPaid`, `service`, `PaymentType` — бинаризация / one-hot encoding
- Удаление переобучающих и малоинформативных признаков:
  - `user_id`, `nm_id`, `CreatedDate`

### Работа с дисбалансом классов
Протестированы методы:
- SMOTE
- Сlass weights
- Clustering-based undersampling

### Выбор моделей
Использовались:
- CatBoost с `class weights`
- LightGBM с `scale pos weight`
- **Итоговое решение**: Non-Redundant Aggregation на основе двух моделей машинного обучения: CatBoost и LightGBM с оптимальным взвешиванием

## 3. Ключевые гиперпараметры
### CatBoost
| Параметр            | Значение |
|---------------------|----------|
| `eval_metric`       | `F1`     |
| `iterations`        | `800`    |
| `depth`             | `9`      |
| `learning_rate`     | `0.1`    |
| `l2_leaf_reg`       | `50`     |
| `scale_pos_weight`  | `9`      |
| `min_data_in_leaf`  | `50`     |
| `max_ctr_complexity`| `3`      |

### LightGBM
| Параметр            | Значение               |
|---------------------|------------------------|
| `objective`         | `binary`               |
| `metric`            | `binary_logloss`       |
| `boosting_type`     | `gbdt`                 |
| `num_leaves`        | `80`                   |
| `max_depth`         | `8`                    |
| `learning_rate`     | `0.1`                  |
| `n_estimators`      | `150`                  |
| `min_child_weight`  | `20`                   |
| `lambda_l2`         | `0.3`                  |
| `min_data_in_leaf`  | `30`                   |
| `scale_pos_weight`  | `6.9`                  |

## 4. Результаты на тестовой выборке
| Модель    | Precision | Recall | F1-score | Confusion Matrix               |
|-----------|-----------|--------|----------|---------------------------------|
| CatBoost  | 84.96     | 6.26   | 11.66    | `[[12434, 1693], [20, 113]]`         |
| LightGBM  | 87.6      | 6.26   | 11.68    | `[[12438, 1693], [16, 113]]`         |
| Ансамбль  | 84.5      | 10.2   | 18.3     | `[[12420, 1621], [34, 185]]`         |

## 5. Результаты
- Для задачи детекции мошенничества (Fraud Detection) была выбрана **Non-Redundant Aggregation (OR-Ensemble)** по следующим ключевым причинам:

1. **Максимизация обнаружения мошеннических операций**  
   В fraud-задачах критически важна **полнота (Recall)**, так как стоимость пропуска мошенничества (False Negative) на порядки выше стоимости ложных срабатываний (False Positive). OR-Ensemble позволяет:
   - Обнаруживать **уникальные случаи**, которые каждая из моделей пропускает по отдельности
   - Увеличивать охват аномалий на 15-25% по сравнению с обычным голосованием

2. **Особенности данных**  
   - Сильный дисбаланс классов (1:5+)
   - Модели часто находят **непересекающиеся паттерны** мошенничества

3. **Ожидаемые метрики**  
   Для нашего решения характерна следующая точность:
   - **Precision**: 84-85% (высокая точность благодаря пост-фильтрации)
   - **Recall**: >10% 
   - **F1-Score**: ~18% 

## 6. Инструкция по запуску
- Инструкции по использованию репозитория и запуску сервиса можно посмотреть в README.md